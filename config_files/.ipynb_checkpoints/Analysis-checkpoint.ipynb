{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs import *\n",
    "from direction_and_file_handleing import *\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import nltk\n",
    "import string\n",
    "import chardet\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def words_frequency(list_of_all_words):\n",
    "    '''\n",
    "    The function used to get all the frequency of each word.\n",
    "    Argument:\n",
    "       list_of_all_words: The whole words of all files strings in one direction\n",
    "   Return\n",
    "       data_frame: the dataframe which have two column of all words and frequency of each word\n",
    "    '''\n",
    "    vect = CountVectorizer().fit(list_of_all_words)\n",
    "    # get the words it self\n",
    "    dict_words = list(vect.vocabulary_.keys())\n",
    "    # get the words frequency\n",
    "    dict_frequency = list(vect.vocabulary_.values())\n",
    "    print(\"Sample of first 10 top words: \", dict_words[:10])\n",
    "    print(\"Sample of first 10 top words frequency: \", dict_frequency[:10])\n",
    "    \n",
    "    # create a dictionary that maps each word to its frequency\n",
    "    words_frequency = {'frequency': dict_frequency, 'words': dict_words}\n",
    "    # create a data frame with 2 columns from the dictionary\n",
    "    data_frame = pd.DataFrame(data=words_frequency)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_rows(df):\n",
    "    '''\n",
    "    Drop all row that not contain on Arabic words\n",
    "    Argument:\n",
    "        df: pandas dataframe that have some columns ans rows\n",
    "    Return:\n",
    "        Return the same data frame but cleaned from cell that contains anything except Arabic words\n",
    "    '''\n",
    "    # drop rows contain numbers\n",
    "    drop_rows = df[df['words'].str.isdigit()].index\n",
    "    df.drop(drop_rows, inplace=True)\n",
    "    \n",
    "    # drop rows contain Chinese and English words\n",
    "    drop_rows = df[df['words'].str.contains('[a-zA-z0-9⺀-⺙⺛-⻳⼀-⿕々〇〡-〩〸-〺〻㐀-䶵一-鿃豈-鶴侮-頻並-龎]',  \n",
    "                                  regex=True)].index\n",
    "    df.drop(drop_rows, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analysis_pipline(direction, save_csv_path):\n",
    "    '''\n",
    "    The pipline to make all of our work in one direction\n",
    "    Argument:\n",
    "        direction: Which direction you need to make an analysis on.\n",
    "        save_csv_path: After the analysis dave the result in csv file.\n",
    "    Return\n",
    "        True once it save the file that cotain the dataframe we reutrned\n",
    "    '''\n",
    "    try:\n",
    "        list_of_all_words_direction = read_direction_analysis(direction)\n",
    "        print(\"==========\")\n",
    "        print(\"The total words are: \", len(list_of_all_words_direction))\n",
    "        print(\"==========\")\n",
    "        data_frame = words_frequency(list_of_all_words_direction)\n",
    "        print(\"The total Unique words now are: \", len(data_frame))\n",
    "        \n",
    "        data_frame =  drop_rows(data_frame)\n",
    "        print(\"After drop Chinese and English words: \",len(data_frame))\n",
    "        \n",
    "#         data_frame.to_csv(save_csv_path + 'words_frequency.csv', index=False)\n",
    "        print(\"#\" * 70)\n",
    "    except Exception as e:\n",
    "        file = open(\"../logs/Analysis_file.log\",\"+a\")\n",
    "        file.write(\"This error related to function analysis_pipline of Analysis_file n\" \n",
    "                   + str(e) + \"\\n\" + \"#\" *99 + \"\\n\") # \"#\" *99 as separated lines\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# analysis_direction_path_tweets\n",
    "def count_tweets_file(direction_path, save_csv_path):\n",
    "    '''\n",
    "    The fcuntion used to get what is the number of tweets per day\n",
    "    Argument:\n",
    "    Direction_path: which direction you need to deal with.\n",
    "    save_csv_path: After we get the count of tweets of each file day,\n",
    "        we have save one file represent this direction.\n",
    "    \n",
    "    '''\n",
    "    all_path_files = os.listdir(direction_path)\n",
    "    counts_tweets = []\n",
    "    file_day = []\n",
    "    for file_path in all_path_files:\n",
    "        file_path = direction_path + file_path\n",
    "        day = re.findall('([0-9]+.csv)', file_path)\n",
    "        day = day[0].split('.')[0]\n",
    "        df = pd.read_csv(file_path, lineterminator='\\n', error_bad_lines=False, encoding='utf-8')\n",
    "        file_day.append(day)\n",
    "        counts_tweets.append(len(df))\n",
    "    dicts = {'file_day': file_day, 'counts_tweets': counts_tweets}\n",
    "    df = pd.DataFrame(data=dicts)\n",
    "    df = df.sort_values(by=['file_day'])\n",
    "#     save_csv_path = save_csv_path +'tweets_per_day.csv'\n",
    "#     df.to_csv(save_csv_path, index=False)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
