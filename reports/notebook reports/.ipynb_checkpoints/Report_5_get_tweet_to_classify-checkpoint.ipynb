{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designed report by Abdelrahman Rezk\n",
    "\n",
    "## COVID-19-Arabic-Tweets-Dataset\n",
    "\n",
    "\n",
    "**We have collected more than 3, 000, 000 tweets from twitter API, besides cleaning these tweets and we have make some analysis to get what is behind these tweets.**\n",
    "\n",
    "\n",
    "\n",
    "- Eng: Ayman Mahgoub\n",
    "- Researcher at electronics research institute\n",
    "- E-mail: <a href = \"mailto:Ayman_mhgb@hotmail.com\"> Ayman Mhgb </a>\n",
    "\n",
    "\n",
    "\n",
    "- Eng: Abdelrahman Rezk\n",
    "- Teaching Assistant at Arab Open University & NLP Engineer\n",
    "- E-mail: <a href = \"Abdelrahmanrezk12011@gmail.com\"> Abdelrahman Rezk </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification \n",
    "\n",
    "After what we have made of the gather, cleaning and analysis these tweets we have separated some random tweets for directions 1 and 2, which will be used for manual labels to generalize this for the problem of classification these tweets into 2 classes [0, 1]. \n",
    "\n",
    "- Zero class for tweets that it not talk about Coronavirus.\n",
    "- One class tweets that talks about Coronavirus.\n",
    "\n",
    "The classification problem will dealing with via multiple Machine Learning Algorithms like Logisitc regression, but at the same time we will trying to measure how will our model is in the way of let these tweets clusters using the unsupervised learning methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** We have impletent just one function in this Report and others we have used from previous work: **\n",
    "\n",
    "- separate_number_of_tweet_each_file\n",
    "- get_tweet_to_classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## separate_number_of_tweet_each_file\n",
    "\n",
    "As we know that each file have multiple of tweets and each file belongs to one of the direction(folder), and we have 4 direction for 4-month start from January to April but what we used as sample is just from the first 2 month or two direction.\n",
    "\n",
    "As we know we can not label all of the tweets, which in each direction more than 100,000 tweets, so based on the Machine learning Supervised and Unsupervised Approach we have map the problem from label just 3000 sample of each direction to train the model on using the Approach of Supervised learning, and at the same time we will use the Approach of Unsupervised tl cluster these tweets into 2 cluster then we will comapre the two approach to each other.\n",
    "\n",
    "So the function takes number_of_tweets as a parameter which is related to a number of files in each direction, and we think of a simple math equation to know if the direction contains all of the days then it will have 30 days so will divide 3000/30 will give us that we need 100 tweets from each file to make the sample from all files which define that our sample is represent all tweets from all files, otherwise the 3000 will divide by the number of files in this direction to know which number of tweets we need from each file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## get_tweet_to_classify\n",
    "\n",
    "After we have been finishing the function separate_number_of_tweet_each_file, and check the result CSV file we that the data do not represent a good sample of the data so we have to make another function and enhance the random way we get the tweet from to arrive after classification to be in balance of the two classes.\n",
    "\n",
    "Function to read all tweets of all files in one direction into one list, then \n",
    "- take random tweets from this list, also for each tweet make some regular expression,\n",
    "    - like replace \\n with just space to make the whole tweets in one line,\n",
    "- then save the result in CSV and  XLS file.\n",
    "\n",
    "The function takes:\n",
    "\n",
    "- direction_read: Which direction you will read files from.\n",
    "- direction_save: After you take the random tweets and make a data frame of it which direction you need to save.\n",
    "- number_of_tweets: which number of tweets at all you need.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
